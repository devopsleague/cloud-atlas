.. _think_gpt:

=================
GPT之思
=================

2023年开始，ChatGPT 3.5到GPt-4，AIGC(AI内容生成)突然间成为引爆业内外的热点，大模型训练后的推理能力，能够完成文字到图形和视屏的双向转换，理解问答，解题和编程。似乎一瞬间， :ref:`machine_learning` 展现出的恐怖能力即将替代我们普通工作者绝大多数岗位。

震惊么？恐惧么？

确实，对于我这样普通的IT工作者而言，大多数能力确实有可能在很短时间内被这种汇聚了历史海量数据训练出的AIGC所打败，但是有没有可能我们自己向前进化，超越并驾驭这场AI狂潮呢？

知己知彼
===========

在我有限的 :ref:`machine_learning` 知识，以及在这个行业中，多少关注技术新闻以及和从事这方面工作的同事交流，对于目前的GPT技术:

- GPT是通过大量的历史数据训练获得的推理能力: 机器并不理解原理(或者说我们至今还不知道为何大量数据的概率能够展现出准确性)，而是通过海量的文档、图片，预测下一个字符或者色点应该是什么

  - 神奇的概率啊，为何海量的文本就能知道下一个文字是什么呢?
  - 目前我觉得AIGC通过概率推理出正确答案，可能只是因为目前探索的领域(绘画、视屏、计算机编程)，人类累积了无数重复相似的资料，所以通过海量数据训练能够让GPT能够通过 **概率** 从上文推理出下一个字符；但是如果是很少有人从事的工作，例如少有人开发的程序逻辑，则GPT会失误

- GPT的惊人能力的核心是概率，但是短板可能也是概率:

  - 就目前而言，GPT只能根据历史数据来训练，通过海量数据的概率来推理出结果: 既然是概率，就有一定的错误可能性，对于艺术类(包括文学)本身无绝对准确的要求，所以GPT可以替代大多数工作，但是对于以准确精度要求的技术领域，GPT还需要专业技能的人来判断
  - 目前应该还没有破解出AI的真正奥义，我们还不能解释海量数据的训练得到的GPT能力的原因，为何有些参数是优化有些是恶化；所以在一段时间内，GPT的出错概率可能还不能满足高精度技术领域要求(但是这个时间有多久不好说)
  - **不过我很担心我们自己的推理能力是不是也是生物意义上的概率，只不过是自然进化赋予我们生物本能的概率判断** ，有没有可能我们还不知道自己的能力就是进化得来的概率本能

- 也许今后只要人类创造过的东西， :ref:`machine_learning` 通过输入这些历史数据都能重复实现，你或许说那我们人就专注于创造，让机器来学习我们的创造完成重复的类似的工作:

  - 大多数像我这样普通的人，或许有时有天马行空的想法，但是缺乏将想法实现的能力、财力和精力；从小受到的训练都是社会分工下的狭窄领域的技能
  - 就目前而言， :ref:`machine_learning` 需要数学和计算机领域极深的造诣，大多数人包括我惊叹于其魔力而难以掌握底层的真正能力

未来世界的幸存者
=================

目前我想象中在未来可能的生存方式:

- 努力拥抱技术变革，不要拒绝(拒绝也没有用)，学习 :ref:`machine_learning` ，至少在工程上能够掌握基本原理和实现，能够自己训练和推理，辅助自己提高工作能力
- 通过GPT来训练自己的编程能力，使得自己能够作为AIGC的判断者: 可能在一段时间内，通过GPT叠加GPT方式来提高准确度精度在技术和成本上难以实现，这或许是我们技术工作者的价值所在(假如AI技术没有再次突破)
- 学习更多领域知识融汇贯通，并且能和他人够协作交流: 目前单一领域的机器学习比较容易实现，很多公司都在细分领域训练AIGC，但是融汇贯通难度较大，暂时可能还不被AIGC替代

随着GPT(AIGC)技术的发展，特别是训练、推理成本不断下降，有可能会比人工(类似最后的判断者)更为经济，作为普通人的压力会越来越大。所以，个人需要掌握这项技术并且能够以普通人的资源抗衡 `利维坦 <https://zh.wikipedia.org/wiki/%E5%88%A9%E7%BB%B4%E5%9D%A6_(%E9%9C%8D%E5%B8%83%E6%96%AF)>`_ 的压迫。
